# 1. 로컬 NUC PC에서 언어 LLM 설치하기

처음 실습에서 사용할 모델은 4비트로 파인튜닝된 모델로써 7B 버전의 경우 4GB이상의 램만 있다면 노트북으로도 동작시킬 수 있습니다.
먼저 자유롭게 해당 모델을 로컬에 설치하고 실제 실행해보는걸 목표로 합니다.



## the installation steps for the model


git clone https://github.com/antimatter15/alpaca.cpp
cd alpaca.cpp

sudo dnf install -y python3-devel python3-setuptools libtiff-devel libjpeg-devel libzip-devel freetype-devel lcms2-devel libwebp-devel tcl-devel tk-devel

wget https://github.com/antimatter15/alpaca.cpp/releases/download/81bd894/alpaca-linux.zip

wget https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml/resolve/main/ggml-alpaca-7b-q4.bin

make chat


### ! If the "wget" command is not working, you can manually download the model files from the respective pages and then move the downloaded files to the "git folder"

https://github.com/antimatter15/alpaca.cpp/releases/tag/81bd894

https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml/blob/main/ggml-alpaca-7b-q4.bin 


## 실행명령어
./chat

## 모델 동작할때

If the model installation and execution have been completed successfully, you can use the chat mode locally to interact with the model and ask questions.



## 트립톤 서버 추론 예제

## the installation steps for the model

sudo dnf install -y python3-devel python3-pip python3-setuptools libjpeg-devel zlib-devel libtiff-devel freetype-devel lcms2-devel libwebp-devel harfbuzz-devel fribidi-devel tcl-devel tk-devel

sudo dnf install -y torch torchvision

To download the example files to your local server, follow these steps:

Download the .py files and labels.txt file to your local machine.

! Place the images in the same directory as the folder. If you placed the images in a different directory, make sure to modify the paths accordingly.



## 다음으로는 트립톤 서버에 배포된 모델을 이용하여 간단한 웹 프레임워크 형태로 실행해보는 것 입니다.






여기까지 완료하셨다면 필수 실습은 모두 완료하셨습니다.
아래부터는 추가적으로 학습을 원하신다면 진행해보시길 바랍니다.



sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm
sudo dnf config-manager --set-enabled epel

sudo dnf install git-lfs

git lfs install

git clone https://huggingface.co/AlekseyKorshuk/vicuna-7b.git
download checkpoint

## edit config file
cd vicuna-7b

vi model_configs/minigpt4_vicuna.yaml

vicuna_weight_path: "/path/to/vicuna_weights/"



