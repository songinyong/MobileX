{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c806e057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Pre-trained ResNet-50 모델 로드\n",
    "resnet50_model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "resnet50_model.eval()\n",
    "\n",
    "# ONNX 형식으로 모델 변환\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "onnx_filename = \"model_repository/resnet50/1/model.onnx\"\n",
    "torch.onnx.export(resnet50_model, dummy_input, onnx_filename, input_names=[\"input\"], output_names=[\"output\"], export_params=True, opset_version=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fadd582f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Inference failed: {\"error\":\"Request for unknown model: 'resnet50' is not found\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2z/2ccfrxv17rsbfpk7btjf9s2c0000gn/T/ipykernel_1312/748231118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/inyong/Desktop/img.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2z/2ccfrxv17rsbfpk7btjf9s2c0000gn/T/ipykernel_1312/748231118.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(input_batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inference failed: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Inference failed: {\"error\":\"Request for unknown model: 'resnet50' is not found\"}"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import json\n",
    "\n",
    "\n",
    "# 이미지를 전처리하고 추론을 위해 데이터를 준비하는 함수\n",
    "def preprocess(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.224, 0.243, 0.264])\n",
    "    ])\n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    return input_batch\n",
    "\n",
    "# 트라이톤 서버로부터 결과를 받아 분류를 출력하는 함수\n",
    "def postprocess(result, topk=5):\n",
    "    probabilities = torch.nn.functional.softmax(torch.tensor(result), dim=1)\n",
    "    topk_prob, topk_indices = torch.topk(probabilities, topk)\n",
    "    topk_prob = topk_prob.numpy().tolist()[0]\n",
    "    topk_indices = topk_indices.numpy().tolist()[0]\n",
    "\n",
    "    with open(\"imagenet_classes.json\") as f:\n",
    "        labels_map = json.load(f)\n",
    "    \n",
    "    for i in range(topk):\n",
    "        print(f\"Class: {labels_map[str(topk_indices[i])]}, Probability: {topk_prob[i]}\")\n",
    "\n",
    "# 추론을 실행하는 함수\n",
    "def infer(input_batch):\n",
    "    url = \"http://triton.default.svc.ops.openark:8000/v2/models/resnet50/infer\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    data = {\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"shape\": list(input_batch.shape),\n",
    "                \"data\": input_batch.numpy().tolist(),\n",
    "            }\n",
    "        ],\n",
    "        \"outputs\": [\n",
    "            {\n",
    "                \"name\": \"output\",\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"shape\": [1, 1000],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(\"Inference failed: \" + response.text)\n",
    "    response_data = json.loads(response.text)\n",
    "    result = response_data[\"outputs\"][0][\"data\"]\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"/Users/inyong/Desktop/img.jpg\"\n",
    "    input_batch = preprocess(image_path)\n",
    "    result = infer(input_batch)\n",
    "    postprocess(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e692cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
