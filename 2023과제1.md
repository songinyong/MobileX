# 1. 로컬 NUC PC에서 언어 LLM 설치하기

처음 실습에서 사용할 모델은 4비트로 파인튜닝된 모델로써 7B 버전의 경우 4GB이상의 램만 있다면 노트북으로도 동작시킬 수 있습니다.
먼저 자유롭게 해당 모델을 로컬에 설치하고 실제 실행해보는걸 목표로 합니다.



## the installation steps for the model


git clone https://github.com/antimatter15/alpaca.cpp
cd alpaca.cpp

sudo dnf install -y python3-devel python3-setuptools libtiff-devel libjpeg-devel libzip-devel freetype-devel lcms2-devel libwebp-devel tcl-devel tk-devel

wget https://github.com/antimatter15/alpaca.cpp/releases/download/81bd894/alpaca-linux.zip
wget https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml/resolve/main/ggml-alpaca-7b-q4.bin

make chat


### ! If the "wget" command is not working, you can manually download the model files from the respective pages and then move the downloaded files to the "git folder"

https://github.com/antimatter15/alpaca.cpp/releases/tag/81bd894
https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml/blob/main/ggml-alpaca-7b-q4.bin 


## 실행명령어
./chat

## 모델 동작할때

If the model installation and execution have been completed successfully, you can use the chat mode locally to interact with the model and ask questions.



## 트립톤 서버 추론 예제

## the installation steps for the model

sudo dnf install -y python3-devel python3-pip python3-setuptools libjpeg-devel zlib-devel libtiff-devel freetype-devel lcms2-devel libwebp-devel harfbuzz-devel fribidi-devel tcl-devel tk-devel

sudo dnf install -y torch torchvision



실제 트립톤 서버에 배포단계를 진행합니다.

sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm
sudo dnf config-manager --set-enabled epel

sudo dnf install git-lfs

git lfs install

git clone https://huggingface.co/AlekseyKorshuk/vicuna-7b.git
download checkpoint

## edit config file
cd vicuna-7b

vi model_configs/minigpt4_vicuna.yaml

vicuna_weight_path: "/path/to/vicuna_weights/"



